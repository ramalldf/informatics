{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading state sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "stateScores= json.load(open('game2_q1aShortSent.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import the state coordinates in Bokeh and see if we can scatter these '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load raw data into dataframe\n",
    "df= pd.DataFrame.from_dict(stateScores, orient= 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DC</th>\n",
       "      <th>WI</th>\n",
       "      <th>WV</th>\n",
       "      <th>HI</th>\n",
       "      <th>FL</th>\n",
       "      <th>WY</th>\n",
       "      <th>NH</th>\n",
       "      <th>NJ</th>\n",
       "      <th>...</th>\n",
       "      <th>MN</th>\n",
       "      <th>MI</th>\n",
       "      <th>KS</th>\n",
       "      <th>MT</th>\n",
       "      <th>MP</th>\n",
       "      <th>MS</th>\n",
       "      <th>SC</th>\n",
       "      <th>KY</th>\n",
       "      <th>OR</th>\n",
       "      <th>SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   WA  DE  DC  WI  WV  HI  FL  WY  NH  NJ ...  MN  MI  KS  MT  MP  MS  SC  KY  \\\n",
       "0   0   0  -1   0   2  -1  -1 NaN   0   8 ...   1   0   0   5 NaN   0   0   0   \n",
       "1   2 NaN   0   0  -3   1  -2 NaN NaN  -8 ...   2   0   0 NaN NaN   0  -1   0   \n",
       "2   0 NaN   1   4  -1 NaN   0 NaN NaN   2 ...   0  -1  -4 NaN NaN   0   5   0   \n",
       "\n",
       "   OR  SD  \n",
       "0   1   0  \n",
       "1   0 NaN  \n",
       "2   0 NaN  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2= df.transpose()\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize the data on a map easily, we'll drop the non-continental states and territories. First we'll drop them from the map coordinates from bokeh, and then from the dataframe df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First delete/exclude from the bokeh coordinate dictionary and sort them alphabetically\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.sampledata.us_states import data as states\n",
    "\n",
    "del states[\"HI\"]\n",
    "del states[\"AK\"]\n",
    "\n",
    "EXCLUDED = (\"ak\", \"hi\", \"pr\", \"gu\", \"vi\", \"mp\", \"as\")#Exclude territories\n",
    "\n",
    "import collections#This will allow us to order our states to match coordinates of coord library with data\n",
    "\n",
    "ordStates= collections.OrderedDict(sorted(states.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now exclude Hawaii, Alaska, and territories from our dataframe\n",
    "df3= df2.drop(['HI','AK','PR','GU','VI','MP','AS','NA'], axis= 1)#For some reason we also have a 'NA' column, drop that too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll count the number of tweets in in each state in df3 and calculate the mean tweet score for all the columns/states/series (will ignore NaN's, but output is NaN if the list for a state was empty). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfCount= df3.count()\n",
    "dfMean= df3.mean()\n",
    "#zip(dfCount, dfMean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have three dataframes: df3 = filtered data, dfCount = tweet count for each state in df3, dfMean= mean tweet score for each state in df3.  We'll use these to build our map and <strong>scale and normalize our tweet sentiment score data</strong>.\n",
    "Since some of our values are negative, we'll account for that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First I'll convert this to a dictionary to play with just the values and order the dictionary to match ordStates\n",
    "dfMeanDict= dfMean.to_dict()\n",
    "ordMeanDict= collections.OrderedDict(sorted(dfMeanDict.items()))\n",
    "\n",
    "#I'll also turn the item values into lists to make it easy to normalize scores\n",
    "ordScoreKey= ordMeanDict.keys()\n",
    "ordMeanScore= ordMeanDict.values()\n",
    "\n",
    "#Now we'll calculate the min scores to help us normalize the data\n",
    "minScore= min(ordMeanScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The min and max values in our lexicon are -5 and +5\n",
    "#Thus, first we'll make all values positive by adding 5, and normalize by dividing by 10\n",
    "normScores= ordMeanScore#Shifts baseline scores by absolute value of minimum score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get weight after converting count dictionary and sorting based on key, then taking values like we did with scores\n",
    "weights= dfCount.to_dict()#Convert to dict\n",
    "orderedCounts= collections.OrderedDict(sorted(weights.items())).values()#Sort dict by key, take values list\n",
    "weights= np.float64(orderedCounts)/max(orderedCounts)#Normalize weight by max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's check if our dictionaries match\n",
    "#zip(ordScoreKey,ordStates.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now we have a sorted dictionary for our state coordinates (ordStates), a list of normalized tweetscores whose values match the order of the dictionary (normScores), and a list of corresponding weights for said scores (weights). We can now visualize the data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here, we'll split the coordinates of all the states into x,y lists and initialize our figure object\n",
    "state_xs = [ordStates[code][\"lons\"] for code in ordStates]\n",
    "state_ys = [ordStates[code][\"lats\"] for code in ordStates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a list of colors that we'll use to represent tweet score values. We'll use the cmap object to return a RGBA value depending on what value from 0 to 1 we feed it from our normalized tweet score list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Below we'll set the range for the colormap that we use\n",
    "#Although min and max values for sentiments are -5, and +5, \n",
    "#it'll be much easier to visualize changes if we narrow the working range, say to -1.5:1.5\n",
    "import matplotlib\n",
    "norm = matplotlib.colors.Normalize(vmin=-1.5, vmax=1.5)\n",
    "\n",
    "cmap= matplotlib.cm.get_cmap('bwr')#Initialize cmap object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35294117647058826"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normScores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colorScore= []#Initialize list\n",
    "for i in range(0,len(normScores)):\n",
    "    if np.isnan(normScores[i]):#If the normScores value is nan (no tweets), return white (not in 'viridis' colormap)\n",
    "        colorScore.append('#000000')\n",
    "        \n",
    "    else:\n",
    "        colorScore.append(matplotlib.colors.rgb2hex(cmap(norm(normScores[i]))[:3]))\n",
    "# print 'Score, Viridis hex value'\n",
    "# zip(normScores,colorScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the states have the same number of tweets, thus we'll need to represent this in our map. The alpha transparency property will be a good way to scale the color intensity of each state based on the weights we calculated for each state. The more transparent the color, the fewer tweets it generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "#We'll now make the source for the info on our hover\n",
    "source= ColumnDataSource(data= dict(stateKey=ordScoreKey, counts=orderedCounts, score=ordMeanScore))\n",
    "\n",
    "hover= HoverTool(tooltips= [(\"State\", \"@stateKey\"), (\"Avg Tweet Score\", \"@score\"), (\"# of Tweets\", \"@counts\")])\n",
    "\n",
    "p = figure(title=\"Twitter Sentiment Scores full bwr \", tools=[hover, 'wheel_zoom', 'pan', 'reset'], toolbar_location=\"left\",\n",
    "           plot_width=1100, plot_height=700)\n",
    "\n",
    "#Plot map and use color list to assign colors\n",
    "p.patches(state_xs, state_ys, line_color= 'black', color= colorScore, source= source)#, fill_alpha= alphaWeights)\n",
    "#This part here is the tricky part ,we must take the order listed by states and match it with our score/weight order\n",
    "\n",
    "output_file(\"choropleth.html\", title=\"choropleth.py example\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following will be additional analysis for the scatterplots for just a few teams/states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3= df2[['CA','OK','VA','DC','OH']]\n",
    "df3.tail(3)\n",
    "sns.violinplot(df3)#This works but sns.swarmplot doesn't says index 166 out of bounds?\n",
    "sns.boxplot(df3)#Look here: http://web.stanford.edu/~mwaskom/software/seaborn/generated/seaborn.swarmplot.html \n",
    "plt.ylabel('Tweet Sentiment Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra blocks of code I deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
